import matplotlib
matplotlib.use('Agg')
import gradio as gr
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from configs.ui import build_config_ui
from src.audio.ui import build_audio_ui, get_tts
from src.brain.ui import build_brain_ui, user_input_handler, brain_think_handler
from src.avatar.ui import build_avatar_ui, get_current_avatar, load_a2f_config
from src.avatar.engine import get_engine

# === æ¡¥æ¥å‡½æ•° ===
def tts_bridge(text, ref_audio, ref_text):
    if not text or not ref_audio: return None
    tts = get_tts() 
    if not tts: return None
    output_path = os.path.join("assets", "reply.wav")
    return tts.speak(text, ref_audio, ref_text, output_file=output_path)

def video_bridge(audio_path):
    # 1. ç›´æ¥ä» JSON æ–‡ä»¶è¯»å–æœ€æ–°çš„é…ç½®
    config = load_a2f_config()
    
    engine_name = config.get("engine", "SadTalker")
    img_path = config.get("img")

    if not img_path:
        raise ValueError("è¯·å…ˆåœ¨'å½¢è±¡æ¿€æ´»'é¢æ¿ä¸Šä¼ å›¾ç‰‡å¹¶ç‚¹å‡»'æ¿€æ´»é…ç½®'")

    # 2. ä¼ å…¥å¼•æ“åç§°ï¼Œä¿®å¤ TypeError
    engine = get_engine(engine_name)
    
    # 3. æ ¹æ®ä¸åŒå¼•æ“ä¼ å…¥å¯¹åº”å‚æ•°
    if engine_name == "SadTalker":
        video_path = engine.generate(
            img=img_path, 
            audio=audio_path, 
            out_dir="results",
            use_still=config.get("still", False),
            use_enhancer=config.get("enhancer", True)
        )
    elif engine_name == "MuseTalk":
        video_path = engine.generate(
            img=img_path, 
            audio=audio_path, 
            out_dir="results",
            bbox_shift=config.get("bbox", 0)
        )
    
    return video_path

def create_ui():
    with gr.Blocks(title="guanhelujue", theme=gr.themes.Soft()) as demo:
        with gr.Tabs():
            # Tab 1: Config
            with gr.TabItem("âš™ï¸ 1. ç³»ç»Ÿé…ç½®"):
                build_config_ui()

            # Tab 2: Avatar (æ–°å¢)
            with gr.TabItem("ğŸ“¸ 2. å½¢è±¡è®¾å®š"):
                # å­˜æ–‡ä»¶ç³»ç»Ÿï¼ˆå½¢è±¡è®¾å®šï¼‰
                build_avatar_ui()

            # Tab 3: TTS
            with gr.TabItem("ğŸ™ï¸ 3. è¯­éŸ³éƒ¨ç½²"):
                ref_audio, ref_text = build_audio_ui()

            # Tab 4: Chat (æœ€ç»ˆæ•ˆæœ)
            with gr.TabItem("ğŸ’¬ 4. è§†é¢‘å¯¹è¯"):
                with gr.Row():
                    # å·¦ä¾§ï¼šè§†é¢‘æ’­æ”¾å™¨
                    with gr.Column(scale=1):
                        video_display = gr.Video(
                            label="æ•°å­—äººå®æ—¶æ¼”ç»", 
                            autoplay=True,
                            height=500
                        )
                    
                    # å³ä¾§ï¼šå¯¹è¯æ¡†
                    with gr.Column(scale=2):
                        chatbot, msg_input, submit_btn, clear_btn = build_brain_ui()

        # === æ ¸å¿ƒå¤„ç†é“¾ ===
        def processing_chain(history, ref_audio, ref_text):
            # 1. æ€è€ƒ (æµå¼å‡ºå­—)
            generator = brain_think_handler(history)
            final_text = ""
            for update_history, current_text in generator:
                final_text = current_text
                # æ­¤æ—¶è§†é¢‘æ¡†ä¸åŠ¨
                yield update_history, None 
            
            # 2. è¯´è¯ (ç”ŸæˆéŸ³é¢‘)
            audio_path = None
            if ref_audio and final_text:
                audio_path = tts_bridge(final_text, ref_audio, ref_text)
            
            # 3. æ¼”æˆ (ç”Ÿæˆè§†é¢‘)
            if audio_path:
                video_path = video_bridge(audio_path)
                if video_path:
                    # æ’­æ”¾è§†é¢‘
                    yield update_history, video_path
                else:
                    print("âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥")
                    yield update_history, None

        # === ç»‘å®š ===
        inputs_list = [chatbot, ref_audio, ref_text]
        outputs_list = [chatbot, video_display]

        submit_btn.click(
            user_input_handler, [msg_input, chatbot], [msg_input, chatbot]
        ).then(
            processing_chain, inputs_list, outputs_list
        )

        msg_input.submit(
            user_input_handler, [msg_input, chatbot], [msg_input, chatbot]
        ).then(
            processing_chain, inputs_list, outputs_list
        )
        
        clear_btn.click(lambda: [], None, chatbot)

    return demo

if __name__ == "__main__":
    ui = create_ui()
    ui.queue()
    ui.launch(inbrowser=True, server_name="127.0.0.1", server_port=7860)