import os
import sys
import requests
import shutil
import hashlib
import time

# === 1. MuseTalk ä¸“ç”¨ï¼šæ–‡ä»¶æ¸…å• (å¢å¼ºç‰ˆï¼šæ”¯æŒå“ˆå¸Œæ ¡éªŒ) ===
# å»ºè®®ï¼šå¦‚æœä½ çŸ¥é“ç¡®åˆ‡çš„ SHA256ï¼Œå¡«å…¥ "hash" å­—æ®µå¯å¼€å¯ä¸¥æ ¼æ ¡éªŒ
# å¦‚æœä¸çŸ¥é“ hashï¼Œè„šæœ¬ä¼šè‡ªåŠ¨ä½¿ç”¨ "Content-Length" (æ–‡ä»¶å¤§å°) è¿›è¡Œå¼ºæ ¡éªŒ
MUSETALK_COMPONENTS = [
    # === 1. MuseTalk ä¸»æ¨¡å‹ ===
    {
        "url": "https://huggingface.co/TMElyralab/MuseTalk/resolve/main/musetalk/pytorch_model.bin",
        "path": "models/musetalk/pytorch_model.bin"
    },
    {
        "url": "https://huggingface.co/TMElyralab/MuseTalk/resolve/main/musetalk/musetalk.json",
        "path": "models/musetalk/config.json"
    },
    {
        "url": "https://huggingface.co/TMElyralab/MuseTalk/resolve/main/musetalkV15/unet.pth",
        "path": "models/musetalkV15/unet.pth"
    },
    {
        "url": "https://huggingface.co/TMElyralab/MuseTalk/resolve/main/musetalkV15/musetalk.json",
        "path": "models/musetalkV15/musetalk.json"
    },

    # === 2. SD-VAE ===
    {
        "url": "https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.bin",
        "path": "models/sd-vae/diffusion_pytorch_model.bin"
    },
    {
        "url": "https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/config.json",
        "path": "models/sd-vae/config.json"
    },

    # === 3. DWPose ===
    {
        "url": "https://huggingface.co/yzd-v/DWPose/resolve/main/dw-ll_ucoco_384.pth",
        "path": "models/dwpose/dw-ll_ucoco_384.pth"
    },

    # === 4. Face Parsing (å·²æ›¿æ¢ä¸ºå›½å†…é•œåƒæºï¼Œè§£å†³ä¸‹è½½ä¸åŠ¨çš„é—®é¢˜) ===
    {
        "url": "https://hf-mirror.com/ManyOtherFunctions/face-parse-bisent/resolve/main/79999_iter.pth",
        "path": "models/face-parse-bisent/79999_iter.pth"
    },
    {
        "url": "https://download.pytorch.org/models/resnet18-5c106cde.pth",
        "path": "models/face-parse-bisent/resnet18-5c106cde.pth"
    },

    # === 5. Whisper ===
    {
        "url": "https://huggingface.co/openai/whisper-tiny/resolve/main/pytorch_model.bin",
        "path": "models/whisper/pytorch_model.bin"
    },
    {
        "url": "https://huggingface.co/openai/whisper-tiny/resolve/main/config.json",
        "path": "models/whisper/config.json"
    },
    {
        "url": "https://huggingface.co/openai/whisper-tiny/resolve/main/preprocessor_config.json",
        "path": "models/whisper/preprocessor_config.json"
    },

    # === 6. Syncnet ===
    {
        "url": "https://huggingface.co/ByteDance/LatentSync/resolve/main/latentsync_syncnet.pt",
        "path": "models/syncnet/latentsync_syncnet.pt"
    }
]

MODEL_MAP = {
    "SadTalker-V0.0.2 (æ ¸å¿ƒæ¨¡å‹)": {
        "ms": "vvbc/SadTalker_Checkpoints",
        "hf": "vinthony/SadTalker-V002rc",
        "dir": "checkpoints",
        "engine": "SadTalker"
    },
    "GFPGAN-Weights (é¢éƒ¨å¢å¼º)": {
        "ms": "damo/cv_gfpgan_image-restoration",
        "hf": "TencentARC/GFPGAN",
        "dir": "gfpgan",
        "engine": "SadTalker"
    },
    "MuseTalk (å®Œæ•´æƒé‡åŒ…)": {
        "type": "composite",
        "engine": "MuseTalk"
    }
}

def calculate_file_hash(filepath, algorithm="sha256"):
    """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼"""
    hash_func = getattr(hashlib, algorithm)()
    with open(filepath, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_func.update(chunk)
    return hash_func.hexdigest()

def format_size(bytes_size):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if bytes_size < 1024:
            return f"{bytes_size:.2f}{unit}"
        bytes_size /= 1024
    return f"{bytes_size:.2f}TB"

def _smart_download(url, dest_path, expected_hash=None):
    """
    ğŸ”¥ ç¡¬æ ¸ä¸‹è½½å™¨ï¼šæ”¯æŒ Header é¢„æ£€ã€æ–­ç‚¹ç»­ä¼ ã€å“ˆå¸Œæ ¡éªŒã€é€Ÿåº¦æ˜¾ç¤º
    """
    os.makedirs(os.path.dirname(dest_path), exist_ok=True)
    filename = os.path.basename(dest_path)
    
    # === 1. è·å–è¿œç¨‹æ–‡ä»¶ä¿¡æ¯ (Header Pre-flight) ===
    try:
        # ä½¿ç”¨ stream=True ä½†ä¸è¯»å–å†…å®¹ï¼Œåªçœ‹ Header
        # timeout è®¾ç½®ä¸º 10 ç§’ï¼Œé˜²æ­¢è¯·æ±‚å¡æ­»
        head_resp = requests.head(url, timeout=10, allow_redirects=True)
        # æœ‰äº›æœåŠ¡å™¨ä¸æ”¯æŒ HEADï¼Œå¦‚æœ 405/403 åˆ™å°è¯• GET stream
        if head_resp.status_code >= 400:
             head_resp = requests.get(url, stream=True, timeout=10)
             
        remote_size = int(head_resp.headers.get('content-length', 0))
    except Exception as e:
        yield f"    âš ï¸ æ— æ³•è·å–è¿œç¨‹æ–‡ä»¶ä¿¡æ¯: {e}ï¼Œå°è¯•å¼ºåˆ¶ä¸‹è½½...\n"
        remote_size = 0

    # === 2. æœ¬åœ°æ–‡ä»¶æ ¡éªŒ (Size Check + Hash Check) ===
    if os.path.exists(dest_path):
        local_size = os.path.getsize(dest_path)
        
        # 2.1 åŸºç¡€å¤§å°æ ¡éªŒ
        if remote_size > 0:
            if local_size == remote_size:
                # 2.2 è¿›é˜¶å“ˆå¸Œæ ¡éªŒ (å¦‚æœæœ‰)
                if expected_hash:
                    yield f"    ğŸ” æ­£åœ¨æ ¡éªŒå“ˆå¸Œ: {filename}...\n"
                    local_hash = calculate_file_hash(dest_path)
                    if local_hash == expected_hash:
                        yield f"    âœ… æ–‡ä»¶å®Œæ•´ (HashåŒ¹é…): {filename}\n"
                        return
                    else:
                        yield f"    âŒ å“ˆå¸Œä¸åŒ¹é…ï¼Œåˆ é™¤é‡ä¸‹ (æœ¬åœ°:{local_hash[:8]}... vs è¿œç¨‹:{expected_hash[:8]}...)\n"
                        os.remove(dest_path)
                else:
                    yield f"    âœ… æ–‡ä»¶å¤§å°ä¸€è‡´ï¼Œè·³è¿‡: {filename} ({format_size(local_size)})\n"
                    return
            else:
                yield f"    âš ï¸ æ–‡ä»¶ä¸å®Œæ•´ (æœ¬åœ°:{format_size(local_size)} vs è¿œç¨‹:{format_size(remote_size)})ï¼Œé‡æ–°ä¸‹è½½...\n"
                os.remove(dest_path) # å¤§å°ä¸å¯¹ï¼Œç›´æ¥åˆ äº†é‡ä¸‹
        else:
            # å¦‚æœè¿œç¨‹æ²¡ç»™å¤§å°ï¼Œåªèƒ½ç²—ç•¥åˆ¤æ–­
            if local_size > 1024: # å¤§äº1KBå‹‰å¼ºç®—å­˜åœ¨
                yield f"    â„¹ï¸ æ— æ³•è·å–è¿œç¨‹å¤§å°ï¼Œæœ¬åœ°æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {filename}\n"
                return

    # === 3. å¼€å§‹ä¸‹è½½ (å¸¦ ASCII è¿›åº¦æ¡) ===
    try:
        start_time = time.time()
        response = requests.get(url, stream=True, timeout=60)
        response.raise_for_status()
        
        # å†æ¬¡ç¡®è®¤å¤§å°ï¼ˆGET è¯·æ±‚é€šå¸¸æ¯” HEAD å‡†ï¼‰
        total_size = int(response.headers.get('content-length', remote_size))
        
        yield f"    â¬‡ï¸ å¼€å§‹ä¸‹è½½: {filename} | å¤§å°: {format_size(total_size)}\n"

        downloaded = 0
        last_print_time = 0
        
        with open(dest_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192*4):
                if chunk:
                    f.write(chunk)
                    downloaded += len(chunk)
                    
                    # è¿›åº¦æ¡é€»è¾‘ï¼šæ¯ 0.5 ç§’æˆ–æ¯ 5% åˆ·æ–°ä¸€æ¬¡ UIï¼Œé¿å…å¡æ­»
                    current_time = time.time()
                    if total_size > 0:
                        percent = int((downloaded / total_size) * 100)
                        if (current_time - last_print_time > 1.0) or (percent % 10 == 0 and percent != 0):
                            # è®¡ç®—é€Ÿåº¦
                            elapsed = current_time - start_time
                            speed = downloaded / elapsed if elapsed > 0 else 0
                            
                            # ç»˜åˆ¶ ASCII è¿›åº¦æ¡
                            bar_len = 20
                            filled_len = int(bar_len * percent / 100)
                            bar = 'â–ˆ' * filled_len + 'â–‘' * (bar_len - filled_len)
                            
                            yield f"      [{bar}] {percent}% | {format_size(speed)}/s\n"
                            last_print_time = current_time

        # === 4. ä¸‹è½½åæœ€ç»ˆæ£€æŸ¥ ===
        if total_size > 0 and os.path.getsize(dest_path) != total_size:
            yield f"    âŒ ä¸‹è½½æ ¡éªŒå¤±è´¥ï¼šå¤§å°ä¸ä¸€è‡´ï¼\n"
            os.remove(dest_path)
        else:
            yield f"    âœ… ä¸‹è½½å®Œæˆ: {filename}\n"
            
    except Exception as e:
        if os.path.exists(dest_path):
            os.remove(dest_path) # å¤±è´¥å°±åˆ ï¼Œä¸ç•™åƒåœ¾
        yield f"    âŒ ç½‘ç»œé”™è¯¯ ({filename}): {e}\n"

def download_avatar_model_handler(source_type, model_key):
    if not model_key:
        yield "âš ï¸ è¯·å…ˆé€‰æ‹©æ¨¡å‹ï¼"
        return

    info = MODEL_MAP.get(model_key)
    current_dir = os.path.dirname(os.path.abspath(__file__))
    
    if info["engine"] == "MuseTalk":
        engine_root = os.path.join(current_dir, "musetalk")
    else:
        engine_root = os.path.join(current_dir, "sadtalker")
    
    if not os.path.exists(engine_root):
        yield f"âš ï¸ æœªæ‰¾åˆ° {info['engine']} æºç ç›®å½•ï¼Œè¯·å…ˆæ‰§è¡Œå®‰è£…ï¼"
        return

    # === MuseTalk é€»è¾‘ ===
    if info.get("type") == "composite":
        yield f"ğŸš€ å¯åŠ¨ MuseTalk æ™ºèƒ½ä¸‹è½½å™¨ (Smart Verify)...\n"
        
        for item in MUSETALK_COMPONENTS:
            full_path = os.path.join(engine_root, item["path"])
            # å°†é…ç½®é‡Œçš„ url å’Œ hash ä¼ è¿›å»
            for log in _smart_download(item["url"], full_path, item.get("hash")):
                yield log
                
        yield "\nâœ… æ‰€æœ‰ç»„ä»¶æ ¡éªŒ/ä¸‹è½½å®Œæ¯•ï¼"
        return

    # === SadTalker é€»è¾‘ (ModelScope/HF) ===
    target_dir = os.path.join(engine_root, info['dir'])
    repo_id = info["ms"] if source_type == "ModelScope" else info["hf"]
    
    yield f"ğŸš€ [SadTalker] æ­£åœ¨è°ƒç”¨ {source_type} SDK ä¸‹è½½...\n"
    
    try:
        if source_type == "ModelScope":
            from modelscope import snapshot_download
            snapshot_download(repo_id, local_dir=target_dir)
        else:
            from huggingface_hub import snapshot_download
            snapshot_download(repo_id, local_dir=target_dir)
        yield f"\nâœ… ä¸‹è½½å®Œæˆï¼"
    except Exception as e:
        yield f"\nâŒ ä¸‹è½½å¤±è´¥: {e}"