import gradio as gr
from .llm_engine import LLMEngine
import time

_brain_instance = None

def get_brain():
    global _brain_instance
    if _brain_instance is None:
        _brain_instance = LLMEngine()
    return _brain_instance

def build_brain_ui():
    with gr.Column():
        # 1. èŠå¤©çª—å£
        chatbot = gr.Chatbot(
            height=500, 
            type="messages", 
            label="æ•°å­—äººäº¤äº’",
            bubble_full_width=False
        )
        

        # 2. è¾“å…¥åŒº
        with gr.Row():
            msg_input = gr.Textbox(placeholder="è¯·è¾“å…¥æŒ‡ä»¤...", scale=9, autofocus=True)
            submit_btn = gr.Button("å‘é€", variant="primary", scale=1)
        
        clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºè®°å¿†")

    # è¿”å› audio_player ä¾›ä¸»ç¨‹åºè¿çº¿
    return chatbot, msg_input, submit_btn, clear_btn

# ... (user_input_handler å’Œ brain_think_handler é€»è¾‘ä¿æŒä¸å˜ï¼Œä¸éœ€è¦æ”¹) ...
# ä¸ºäº†å®Œæ•´æ€§ï¼Œè¿™é‡Œåˆ—å‡º handler çš„å¼•ç”¨ï¼Œå®é™…ä»£ç è¯·ä¿ç•™ä¹‹å‰çš„é€»è¾‘
def user_input_handler(user_message, history):
    if not user_message: return "", history
    history.append({"role": "user", "content": user_message})
    return "", history

def brain_think_handler(history):
    brain = get_brain()
    history.append({"role": "assistant", "content": ""})
    if not brain:
        history[-1]['content'] = "âŒ å¤§è„‘æœªè¿æ¥"
        yield history, ""
        return
    
    try:
        user_text = history[-2]['content']
        generator = brain.think(user_text)
        if isinstance(generator, str): generator = [generator]
        
        full_response = ""
        for chunk in generator:
            full_response += chunk
            history[-1]['content'] = full_response
            yield history, full_response
            time.sleep(0.005)
    except Exception as e:
        history[-1]['content'] = f"Error: {e}"
        yield history, ""